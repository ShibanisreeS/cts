{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hERywrj9G0pv",
        "outputId": "76dd7fa0-fe38-4714-de09-3f89ac9120b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to\n",
            "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[I 2024-08-18 14:38:11,684] A new study created in memory with name: no-name-ae19f9d8-dec5-440f-bc24-9283249e75d6\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:38:18,682] Trial 0 finished with value: -0.3315739035606384 and parameters: {'xgb_n_estimators': 113, 'xgb_max_depth': 5, 'xgb_learning_rate': 0.003333460688136266, 'xgb_subsample': 0.7544847871862848, 'xgb_colsample_bytree': 0.8466279221852107}. Best is trial 0 with value: -0.3315739035606384.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:38:22,546] Trial 1 finished with value: -0.26663821935653687 and parameters: {'xgb_n_estimators': 131, 'xgb_max_depth': 4, 'xgb_learning_rate': 0.0023956413056890943, 'xgb_subsample': 0.8223411612282591, 'xgb_colsample_bytree': 0.5920150753118457}. Best is trial 0 with value: -0.3315739035606384.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:38:36,304] Trial 2 finished with value: 0.05318188667297363 and parameters: {'xgb_n_estimators': 84, 'xgb_max_depth': 10, 'xgb_learning_rate': 0.000134211176153925, 'xgb_subsample': 0.6451353696600668, 'xgb_colsample_bytree': 0.5038846316551178}. Best is trial 0 with value: -0.3315739035606384.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:38:54,007] Trial 3 finished with value: -0.3825903534889221 and parameters: {'xgb_n_estimators': 168, 'xgb_max_depth': 9, 'xgb_learning_rate': 0.0028925357170765933, 'xgb_subsample': 0.6553486551008533, 'xgb_colsample_bytree': 0.6753276274870013}. Best is trial 3 with value: -0.3825903534889221.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:38:58,789] Trial 4 finished with value: -0.5477126836776733 and parameters: {'xgb_n_estimators': 217, 'xgb_max_depth': 4, 'xgb_learning_rate': 0.0057595454732320955, 'xgb_subsample': 0.7726543891794582, 'xgb_colsample_bytree': 0.6489270620645844}. Best is trial 4 with value: -0.5477126836776733.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:39:00,817] Trial 5 finished with value: -0.524665355682373 and parameters: {'xgb_n_estimators': 59, 'xgb_max_depth': 3, 'xgb_learning_rate': 0.056662686050172745, 'xgb_subsample': 0.5442642293213323, 'xgb_colsample_bytree': 0.9653053420694062}. Best is trial 4 with value: -0.5477126836776733.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:39:07,675] Trial 6 finished with value: -0.7036637663841248 and parameters: {'xgb_n_estimators': 110, 'xgb_max_depth': 7, 'xgb_learning_rate': 0.0767152124334307, 'xgb_subsample': 0.5822689140589097, 'xgb_colsample_bytree': 0.9984308653038272}. Best is trial 6 with value: -0.7036637663841248.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:39:28,107] Trial 7 finished with value: -0.5129438042640686 and parameters: {'xgb_n_estimators': 219, 'xgb_max_depth': 8, 'xgb_learning_rate': 0.0034643678692600276, 'xgb_subsample': 0.8590251357050385, 'xgb_colsample_bytree': 0.9717585790209249}. Best is trial 6 with value: -0.7036637663841248.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:39:41,289] Trial 8 finished with value: -0.6545168161392212 and parameters: {'xgb_n_estimators': 73, 'xgb_max_depth': 10, 'xgb_learning_rate': 0.03150399084571219, 'xgb_subsample': 0.7839852715404103, 'xgb_colsample_bytree': 0.8277187578478972}. Best is trial 6 with value: -0.7036637663841248.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:39:47,891] Trial 9 finished with value: -0.5963758230209351 and parameters: {'xgb_n_estimators': 149, 'xgb_max_depth': 6, 'xgb_learning_rate': 0.00929084510199118, 'xgb_subsample': 0.7862187892670033, 'xgb_colsample_bytree': 0.6876868057633756}. Best is trial 6 with value: -0.7036637663841248.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:40:03,930] Trial 10 finished with value: -0.07198011875152588 and parameters: {'xgb_n_estimators': 255, 'xgb_max_depth': 7, 'xgb_learning_rate': 0.0004015476742919696, 'xgb_subsample': 0.9880809373136652, 'xgb_colsample_bytree': 0.8547710575819352}. Best is trial 6 with value: -0.7036637663841248.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:40:12,378] Trial 11 finished with value: -0.6577717661857605 and parameters: {'xgb_n_estimators': 52, 'xgb_max_depth': 10, 'xgb_learning_rate': 0.07690044816613971, 'xgb_subsample': 0.5012825442082792, 'xgb_colsample_bytree': 0.8339643548244335}. Best is trial 6 with value: -0.7036637663841248.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:40:19,906] Trial 12 finished with value: -0.6818682551383972 and parameters: {'xgb_n_estimators': 103, 'xgb_max_depth': 8, 'xgb_learning_rate': 0.096235537907637, 'xgb_subsample': 0.5023682576212105, 'xgb_colsample_bytree': 0.9977988388975668}. Best is trial 6 with value: -0.7036637663841248.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:40:27,983] Trial 13 finished with value: -0.6327520608901978 and parameters: {'xgb_n_estimators': 108, 'xgb_max_depth': 7, 'xgb_learning_rate': 0.02016377926463791, 'xgb_subsample': 0.5997795564234161, 'xgb_colsample_bytree': 0.9832026951226219}. Best is trial 6 with value: -0.7036637663841248.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:40:38,609] Trial 14 finished with value: -0.7159205675125122 and parameters: {'xgb_n_estimators': 191, 'xgb_max_depth': 8, 'xgb_learning_rate': 0.09990725093902364, 'xgb_subsample': 0.5765941805765186, 'xgb_colsample_bytree': 0.9162782718638423}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:40:50,571] Trial 15 finished with value: -0.672616720199585 and parameters: {'xgb_n_estimators': 297, 'xgb_max_depth': 6, 'xgb_learning_rate': 0.01780939709314599, 'xgb_subsample': 0.6429686746486157, 'xgb_colsample_bytree': 0.9266501721181559}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:41:07,479] Trial 16 finished with value: -0.18080085515975952 and parameters: {'xgb_n_estimators': 203, 'xgb_max_depth': 8, 'xgb_learning_rate': 0.0009543660436323706, 'xgb_subsample': 0.5817977795243492, 'xgb_colsample_bytree': 0.8997244934050097}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:41:23,182] Trial 17 finished with value: -0.7077699899673462 and parameters: {'xgb_n_estimators': 180, 'xgb_max_depth': 9, 'xgb_learning_rate': 0.03960688658852746, 'xgb_subsample': 0.6989736151401384, 'xgb_colsample_bytree': 0.7343366258209041}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:41:40,020] Trial 18 finished with value: -0.7005250453948975 and parameters: {'xgb_n_estimators': 196, 'xgb_max_depth': 9, 'xgb_learning_rate': 0.034700245252955286, 'xgb_subsample': 0.7031666395127172, 'xgb_colsample_bytree': 0.7524703694628267}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:42:07,604] Trial 19 finished with value: -0.6579222679138184 and parameters: {'xgb_n_estimators': 243, 'xgb_max_depth': 9, 'xgb_learning_rate': 0.009654605020724193, 'xgb_subsample': 0.7018227868885197, 'xgb_colsample_bytree': 0.7714907460986243}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:42:22,198] Trial 20 finished with value: -0.6994210481643677 and parameters: {'xgb_n_estimators': 175, 'xgb_max_depth': 8, 'xgb_learning_rate': 0.03738055079562867, 'xgb_subsample': 0.888728624682544, 'xgb_colsample_bytree': 0.7909633741595822}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:42:32,107] Trial 21 finished with value: -0.7036240100860596 and parameters: {'xgb_n_estimators': 149, 'xgb_max_depth': 7, 'xgb_learning_rate': 0.09774434189792774, 'xgb_subsample': 0.5791878073114595, 'xgb_colsample_bytree': 0.9019541287124054}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:42:49,237] Trial 22 finished with value: -0.706433892250061 and parameters: {'xgb_n_estimators': 158, 'xgb_max_depth': 9, 'xgb_learning_rate': 0.05199926657302993, 'xgb_subsample': 0.7027102270700689, 'xgb_colsample_bytree': 0.7063159772740901}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:43:13,375] Trial 23 finished with value: -0.6756763458251953 and parameters: {'xgb_n_estimators': 184, 'xgb_max_depth': 9, 'xgb_learning_rate': 0.01854099207497304, 'xgb_subsample': 0.7111432523777745, 'xgb_colsample_bytree': 0.703045574855371}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:43:30,277] Trial 24 finished with value: -0.7040188312530518 and parameters: {'xgb_n_estimators': 158, 'xgb_max_depth': 9, 'xgb_learning_rate': 0.038596625356032685, 'xgb_subsample': 0.6728840268823695, 'xgb_colsample_bytree': 0.6098333648693558}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:43:44,745] Trial 25 finished with value: -0.6186637282371521 and parameters: {'xgb_n_estimators': 134, 'xgb_max_depth': 8, 'xgb_learning_rate': 0.011214587180539535, 'xgb_subsample': 0.6132487101878293, 'xgb_colsample_bytree': 0.7265550486044628}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:44:07,235] Trial 26 finished with value: -0.7103305459022522 and parameters: {'xgb_n_estimators': 243, 'xgb_max_depth': 9, 'xgb_learning_rate': 0.05154774596553536, 'xgb_subsample': 0.7288515738889967, 'xgb_colsample_bytree': 0.792561975267142}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:44:49,218] Trial 27 finished with value: -0.692411482334137 and parameters: {'xgb_n_estimators': 253, 'xgb_max_depth': 10, 'xgb_learning_rate': 0.02458378647436359, 'xgb_subsample': 0.9092070165155375, 'xgb_colsample_bytree': 0.7871676770888667}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:45:10,324] Trial 28 finished with value: -0.7110289931297302 and parameters: {'xgb_n_estimators': 292, 'xgb_max_depth': 8, 'xgb_learning_rate': 0.05363555479457502, 'xgb_subsample': 0.7396105090981933, 'xgb_colsample_bytree': 0.8885460940540595}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:45:26,990] Trial 29 finished with value: -0.25891977548599243 and parameters: {'xgb_n_estimators': 286, 'xgb_max_depth': 6, 'xgb_learning_rate': 0.0009816583344019606, 'xgb_subsample': 0.7372187270630371, 'xgb_colsample_bytree': 0.8698203033066421}. Best is trial 14 with value: -0.7159205675125122.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:45:37,110] Trial 30 finished with value: -0.7187759876251221 and parameters: {'xgb_n_estimators': 273, 'xgb_max_depth': 5, 'xgb_learning_rate': 0.0647067607616475, 'xgb_subsample': 0.8167321675494179, 'xgb_colsample_bytree': 0.93976631411828}. Best is trial 30 with value: -0.7187759876251221.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:45:47,247] Trial 31 finished with value: -0.7210416793823242 and parameters: {'xgb_n_estimators': 276, 'xgb_max_depth': 5, 'xgb_learning_rate': 0.05610735991052959, 'xgb_subsample': 0.8221739223473472, 'xgb_colsample_bytree': 0.9358329040263758}. Best is trial 31 with value: -0.7210416793823242.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:45:57,227] Trial 32 finished with value: -0.7143155336380005 and parameters: {'xgb_n_estimators': 279, 'xgb_max_depth': 5, 'xgb_learning_rate': 0.05381757877436301, 'xgb_subsample': 0.8237790131890785, 'xgb_colsample_bytree': 0.9434395608162225}. Best is trial 31 with value: -0.7210416793823242.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:46:08,897] Trial 33 finished with value: -0.6335336565971375 and parameters: {'xgb_n_estimators': 278, 'xgb_max_depth': 5, 'xgb_learning_rate': 0.01463188157788351, 'xgb_subsample': 0.8173412520550255, 'xgb_colsample_bytree': 0.9379165507381729}. Best is trial 31 with value: -0.7210416793823242.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:46:17,980] Trial 34 finished with value: -0.7274439930915833 and parameters: {'xgb_n_estimators': 271, 'xgb_max_depth': 5, 'xgb_learning_rate': 0.06722920125863578, 'xgb_subsample': 0.8345746700814414, 'xgb_colsample_bytree': 0.9369967529608694}. Best is trial 34 with value: -0.7274439930915833.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:46:24,035] Trial 35 finished with value: -0.6364871263504028 and parameters: {'xgb_n_estimators': 267, 'xgb_max_depth': 4, 'xgb_learning_rate': 0.025112748862593782, 'xgb_subsample': 0.9219745089333173, 'xgb_colsample_bytree': 0.9323327223568273}. Best is trial 34 with value: -0.7274439930915833.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:46:27,432] Trial 36 finished with value: 0.0292433500289917 and parameters: {'xgb_n_estimators': 237, 'xgb_max_depth': 3, 'xgb_learning_rate': 0.00011741902006196416, 'xgb_subsample': 0.8419978113017086, 'xgb_colsample_bytree': 0.5188046921372851}. Best is trial 34 with value: -0.7274439930915833.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:46:33,506] Trial 37 finished with value: -0.7196590900421143 and parameters: {'xgb_n_estimators': 223, 'xgb_max_depth': 5, 'xgb_learning_rate': 0.07378060607996392, 'xgb_subsample': 0.9524233207216454, 'xgb_colsample_bytree': 0.911054343989938}. Best is trial 34 with value: -0.7274439930915833.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:46:41,856] Trial 38 finished with value: -0.5458711981773376 and parameters: {'xgb_n_estimators': 223, 'xgb_max_depth': 5, 'xgb_learning_rate': 0.004685391705486319, 'xgb_subsample': 0.9734305330956363, 'xgb_colsample_bytree': 0.9578685952187116}. Best is trial 34 with value: -0.7274439930915833.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:46:47,829] Trial 39 finished with value: -0.019265711307525635 and parameters: {'xgb_n_estimators': 263, 'xgb_max_depth': 4, 'xgb_learning_rate': 0.00021695542769472015, 'xgb_subsample': 0.9407683142417658, 'xgb_colsample_bytree': 0.8672128722222683}. Best is trial 34 with value: -0.7274439930915833.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:46:52,723] Trial 40 finished with value: -0.7110334634780884 and parameters: {'xgb_n_estimators': 234, 'xgb_max_depth': 4, 'xgb_learning_rate': 0.06834480121377026, 'xgb_subsample': 0.8772905000970495, 'xgb_colsample_bytree': 0.8199411990482126}. Best is trial 34 with value: -0.7274439930915833.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:46:58,450] Trial 41 finished with value: -0.7185465097427368 and parameters: {'xgb_n_estimators': 204, 'xgb_max_depth': 5, 'xgb_learning_rate': 0.09625566985002479, 'xgb_subsample': 0.8004322253132053, 'xgb_colsample_bytree': 0.9151592642171844}. Best is trial 34 with value: -0.7274439930915833.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:47:04,725] Trial 42 finished with value: -0.7119009494781494 and parameters: {'xgb_n_estimators': 211, 'xgb_max_depth': 5, 'xgb_learning_rate': 0.06548909281547352, 'xgb_subsample': 0.7708748769166119, 'xgb_colsample_bytree': 0.962422511501492}. Best is trial 34 with value: -0.7274439930915833.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:47:17,553] Trial 43 finished with value: -0.6953086853027344 and parameters: {'xgb_n_estimators': 270, 'xgb_max_depth': 6, 'xgb_learning_rate': 0.027416138756336306, 'xgb_subsample': 0.8109991302294639, 'xgb_colsample_bytree': 0.8794482166975273}. Best is trial 34 with value: -0.7274439930915833.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:47:28,275] Trial 44 finished with value: -0.3469848036766052 and parameters: {'xgb_n_estimators': 227, 'xgb_max_depth': 5, 'xgb_learning_rate': 0.0017404418213090747, 'xgb_subsample': 0.8502009252742612, 'xgb_colsample_bytree': 0.9171444002424436}. Best is trial 34 with value: -0.7274439930915833.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:47:36,218] Trial 45 finished with value: -0.7150449752807617 and parameters: {'xgb_n_estimators': 257, 'xgb_max_depth': 4, 'xgb_learning_rate': 0.08022036446509982, 'xgb_subsample': 0.871300911309677, 'xgb_colsample_bytree': 0.975469768862628}. Best is trial 34 with value: -0.7274439930915833.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:47:50,860] Trial 46 finished with value: -0.7183536887168884 and parameters: {'xgb_n_estimators': 300, 'xgb_max_depth': 6, 'xgb_learning_rate': 0.04151447035240166, 'xgb_subsample': 0.7969837140509304, 'xgb_colsample_bytree': 0.9003624293407202}. Best is trial 34 with value: -0.7274439930915833.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:47:56,932] Trial 47 finished with value: -0.6966389417648315 and parameters: {'xgb_n_estimators': 278, 'xgb_max_depth': 3, 'xgb_learning_rate': 0.07224383882485302, 'xgb_subsample': 0.7614537049144566, 'xgb_colsample_bytree': 0.8475326971103823}. Best is trial 34 with value: -0.7274439930915833.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:48:07,279] Trial 48 finished with value: -0.5647506713867188 and parameters: {'xgb_n_estimators': 210, 'xgb_max_depth': 5, 'xgb_learning_rate': 0.006260690385901561, 'xgb_subsample': 0.9561699634262182, 'xgb_colsample_bytree': 0.9995273672937341}. Best is trial 34 with value: -0.7274439930915833.\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1304081968.py:93: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-08-18 14:48:14,926] Trial 49 finished with value: -0.6741576194763184 and parameters: {'xgb_n_estimators': 230, 'xgb_max_depth': 4, 'xgb_learning_rate': 0.04496574245124784, 'xgb_subsample': 0.8390430477880361, 'xgb_colsample_bytree': 0.9640872311230049}. Best is trial 34 with value: -0.7274439930915833.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best R² score:  0.7274439930915833\n",
            "Best hyperparameters:  {'xgb_n_estimators': 271, 'xgb_max_depth': 5, 'xgb_learning_rate': 0.06722920125863578, 'xgb_subsample': 0.8345746700814414, 'xgb_colsample_bytree': 0.9369967529608694}\n",
            "Final MAE: 0.2842\n",
            "Final MSE: 0.1243\n",
            "Final RMSE: 0.3526\n",
            "Final R² Score: 0.7804\n",
            "\n",
            "Sample Input:\n",
            "      AdmissionID PatientGender  \\\n",
            "5852            2          Male   \n",
            "\n",
            "                            PrimaryDiagnosisDescription  CBC_Lymphocytes  \\\n",
            "5852  Exanthema subitum [sixth disease] due to human...              1.3   \n",
            "\n",
            "      CBC_Neutrophils  CBC_Basophils  CBC_Eosinophils  CBC_Hematocrit  \\\n",
            "5852              8.6            0.1              0.1            45.2   \n",
            "\n",
            "      CBC_Hemoglobin  CBC_MCH  ...  METABOLIC_SODIUM  METABOLIC_TOTAL_PROTEIN  \\\n",
            "5852            18.1     37.8  ...             147.8                      9.4   \n",
            "\n",
            "      URINALYSIS_PH  URINALYSIS_RED_BLOOD_CELLS  URINALYSIS_WHITE_BLOOD_CELLS  \\\n",
            "5852            7.4                         3.2                           4.5   \n",
            "\n",
            "      Smoke   BMI  Alcohol  Exercise  Age  \n",
            "5852     No  28.3      Yes        No   30  \n",
            "\n",
            "[1 rows x 36 columns]\n",
            "\n",
            "Sample Prediction:\n",
            "[2.626511]\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "#!pip install symspellpy xgboost imbalanced-learn nltk pandas scikit-learn optuna --quiet\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from symspellpy import SymSpell\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline as imPipeline\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import optuna\n",
        "\n",
        "# Download required NLTK data\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('words')\n",
        "\n",
        "# Initialize SymSpell object\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
        "dictionary_path = nltk.data.find('corpora/words').path + '/en'\n",
        "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1, separator='\\t')\n",
        "\n",
        "# Initialize stop words and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Define text preprocessing functions\n",
        "def correct_spelling(text):\n",
        "    suggestions = sym_spell.lookup_compound(text, max_edit_distance=2)\n",
        "    return suggestions[0].term if suggestions else text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if pd.isnull(text):\n",
        "        return \"\"\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalpha() and word not in stop_words]\n",
        "    processed_text = ' '.join(tokens)\n",
        "    processed_text = correct_spelling(processed_text)\n",
        "    return processed_text\n",
        "\n",
        "# Load and preprocess dataset\n",
        "df = pd.read_csv(r\"C:\\Users\\HP\\Downloads\\targetfinaldataset1 (1).csv\")\n",
        "df = df.drop(df.columns[:3], axis=1)\n",
        "df = df.drop(columns=['AdmissionStartDate', 'PatientDateOfBirth', 'PrimaryDiagnosisCode'])\n",
        "df['PrimaryDiagnosisDescription'] = df['PrimaryDiagnosisDescription'].fillna('')\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = df.drop('RiskScore', axis=1)\n",
        "y = df['RiskScore']\n",
        "\n",
        "# Identify categorical, numerical, and text features\n",
        "text_feature = 'PrimaryDiagnosisDescription'\n",
        "categorical_features = X.select_dtypes(include=['object']).drop(columns=[text_feature]).columns.tolist()\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Define pipelines for different types of data\n",
        "text_pipeline = imPipeline(steps=[\n",
        "    ('preprocess', FunctionTransformer(lambda x: x.apply(preprocess_text))),\n",
        "    ('tfidf', TfidfVectorizer(max_features=500))\n",
        "])\n",
        "\n",
        "numerical_pipeline = imPipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_pipeline = imPipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine all preprocessing steps\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('text', text_pipeline, text_feature),\n",
        "    ('num', numerical_pipeline, numerical_features),\n",
        "    ('cat', categorical_pipeline, categorical_features)\n",
        "])\n",
        "\n",
        "# Define the Optuna objective function\n",
        "def objective(trial):\n",
        "    xgb_params = {\n",
        "        'n_estimators': trial.suggest_int('xgb_n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('xgb_max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 1e-4, 1e-1),\n",
        "        'subsample': trial.suggest_float('xgb_subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.5, 1.0)\n",
        "    }\n",
        "\n",
        "    xgb_model = XGBRegressor(\n",
        "        objective='reg:squarederror',\n",
        "        random_state=42,\n",
        "        **xgb_params\n",
        "    )\n",
        "\n",
        "    pipeline = imPipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('undersample', RandomUnderSampler(random_state=42)),\n",
        "        ('model', xgb_model)\n",
        "    ])\n",
        "\n",
        "    X_sub, _, y_sub, _ = train_test_split(X, y, test_size=0.8, random_state=42)\n",
        "    X_train_sub, X_val_sub, y_train_sub, y_val_sub = train_test_split(X_sub, y_sub, test_size=0.2, random_state=42)\n",
        "\n",
        "    pipeline.fit(X_train_sub, y_train_sub)\n",
        "    y_val_pred = pipeline.predict(X_val_sub)\n",
        "\n",
        "    r2 = r2_score(y_val_sub, y_val_pred)\n",
        "    return -r2\n",
        "\n",
        "# Create an Optuna study and optimize it\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "best_trial = study.best_trial\n",
        "\n",
        "print(\"Best R² score: \", -best_trial.value)\n",
        "print(\"Best hyperparameters: \", best_trial.params)\n",
        "\n",
        "xgb_best_params = {key.replace('xgb_', ''): value for key, value in best_trial.params.items()}\n",
        "\n",
        "xgb_best = XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    random_state=42,\n",
        "    **xgb_best_params\n",
        ")\n",
        "\n",
        "pipeline_best = imPipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('undersample', RandomUnderSampler(random_state=42)),\n",
        "    ('model', xgb_best)\n",
        "])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "pipeline_best.fit(X_train, y_train)\n",
        "\n",
        "y_test_pred_best = pipeline_best.predict(X_test)\n",
        "\n",
        "mae_best = mean_absolute_error(y_test, y_test_pred_best)\n",
        "mse_best = mean_squared_error(y_test, y_test_pred_best)\n",
        "rmse_best = np.sqrt(mse_best)\n",
        "r2_best = r2_score(y_test, y_test_pred_best)\n",
        "\n",
        "print(f\"Final MAE: {mae_best:.4f}\")\n",
        "print(f\"Final MSE: {mse_best:.4f}\")\n",
        "print(f\"Final RMSE: {rmse_best:.4f}\")\n",
        "print(f\"Final R² Score: {r2_best:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Input:\n",
            "      AdmissionID PatientGender  \\\n",
            "5852            2          Male   \n",
            "\n",
            "                            PrimaryDiagnosisDescription  CBC_Lymphocytes  \\\n",
            "5852  Exanthema subitum [sixth disease] due to human...              1.3   \n",
            "\n",
            "      CBC_Neutrophils  CBC_Basophils  CBC_Eosinophils  CBC_Hematocrit  \\\n",
            "5852              8.6            0.1              0.1            45.2   \n",
            "\n",
            "      CBC_Hemoglobin  CBC_MCH  ...  METABOLIC_SODIUM  METABOLIC_TOTAL_PROTEIN  \\\n",
            "5852            18.1     37.8  ...             147.8                      9.4   \n",
            "\n",
            "      URINALYSIS_PH  URINALYSIS_RED_BLOOD_CELLS  URINALYSIS_WHITE_BLOOD_CELLS  \\\n",
            "5852            7.4                         3.2                           4.5   \n",
            "\n",
            "      Smoke   BMI  Alcohol  Exercise  Age  \n",
            "5852     No  28.3      Yes        No   30  \n",
            "\n",
            "[1 rows x 36 columns]\n",
            "\n",
            "Sample Prediction:\n",
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\545536593.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(int(sample_prediction.round()))\n"
          ]
        }
      ],
      "source": [
        "# Preprocess sample input and predict\n",
        "def preprocess_sample(sample, preprocessor):\n",
        "    # Transform sample using the preprocessor pipeline\n",
        "    sample_preprocessed = preprocessor.transform(sample)\n",
        "    return sample_preprocessed\n",
        "\n",
        "sample_input = X_test.iloc[[0]]\n",
        "sample_input_preprocessed = preprocess_sample(sample_input, preprocessor)\n",
        "sample_prediction = xgb_best.predict(sample_input_preprocessed)\n",
        "\n",
        "print(\"\\nSample Input:\")\n",
        "print(sample_input)\n",
        "print(\"\\nSample Prediction:\")\n",
        "print(int(sample_prediction.round()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9GcvCPiMhU7",
        "outputId": "c3ee4e8f-bdd3-414a-a076-bad6f3627f5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Input:\n",
            "       AdmissionID PatientGender           PrimaryDiagnosisDescription  \\\n",
            "15791            2        Female  Erythema infectiosum [fifth disease]   \n",
            "\n",
            "       CBC_Lymphocytes  CBC_Neutrophils  CBC_Basophils  CBC_Eosinophils  \\\n",
            "15791              4.0              7.7            0.1              0.2   \n",
            "\n",
            "       CBC_Hematocrit  CBC_Hemoglobin  CBC_MCH  ...  METABOLIC_SODIUM  \\\n",
            "15791            43.7            17.7     35.0  ...             145.8   \n",
            "\n",
            "       METABOLIC_TOTAL_PROTEIN  URINALYSIS_PH  URINALYSIS_RED_BLOOD_CELLS  \\\n",
            "15791                      6.2            7.1                         1.2   \n",
            "\n",
            "       URINALYSIS_WHITE_BLOOD_CELLS  Smoke   BMI  Alcohol  Exercise  Age  \n",
            "15791                           3.9    Yes  18.7      Yes        No   36  \n",
            "\n",
            "[1 rows x 36 columns]\n",
            "\n",
            "Sample Prediction:\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\1498926958.py:8: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(int(sample_prediction.round()))\n"
          ]
        }
      ],
      "source": [
        "sample_input = X_test.iloc[[898]]\n",
        "sample_input_preprocessed = preprocess_sample(sample_input, preprocessor)\n",
        "sample_prediction = xgb_best.predict(sample_input_preprocessed)\n",
        "\n",
        "print(\"\\nSample Input:\")\n",
        "print(sample_input)\n",
        "print(\"\\nSample Prediction:\")\n",
        "print(int(sample_prediction.round()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FggwcqLdMCHa",
        "outputId": "2f02e942-6f24-481a-923c-5bd3d9327344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction is correct\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\375239615.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  if int(sample_prediction.round())==y_test.iloc[898]:\n"
          ]
        }
      ],
      "source": [
        "if int(sample_prediction.round())==y_test.iloc[898]:\n",
        "    print(\"Prediction is correct\")\n",
        "else:\n",
        "    print(\"Prediction is incorrect\")\n",
        "print(y_test.iloc[898])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "refW_HFwMObY"
      },
      "outputs": [],
      "source": [
        "def preprocess_text_column(column):\n",
        "    return column.apply(preprocess_text)\n",
        "\n",
        "# Update the text pipeline to use the named function\n",
        "text_pipeline = imPipeline(steps=[\n",
        "    ('preprocess', FunctionTransformer(preprocess_text_column)),\n",
        "    ('tfidf', TfidfVectorizer(max_features=500))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine all preprocessing steps\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('text', text_pipeline, text_feature),\n",
        "    ('num', numerical_pipeline, numerical_features),\n",
        "    ('cat', categorical_pipeline, categorical_features)\n",
        "])\n",
        "\n",
        "pipeline_best = imPipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('undersample', RandomUnderSampler(random_state=42)),\n",
        "    ('model', xgb_best)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitted model and pipeline saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "pipeline_best.fit(X_train, y_train)\n",
        "\n",
        "# Save the fitted pipeline as a pickle file\n",
        "with open('xgb_pipeline.pkl', 'wb') as f:\n",
        "    pickle.dump(pipeline_best, f)\n",
        "\n",
        "print(\"Fitted model and pipeline saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitted model and pipeline loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Load the pipeline and model from the pickle file\n",
        "with open('xgb_pipeline.pkl', 'rb') as f:\n",
        "    loaded_pipeline = pickle.load(f)\n",
        "\n",
        "print(\"Fitted model and pipeline loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['AdmissionID', 'PatientGender', 'PrimaryDiagnosisDescription', 'CBC_Lymphocytes', 'CBC_Neutrophils', 'CBC_Basophils', 'CBC_Eosinophils', 'CBC_Hematocrit', 'CBC_Hemoglobin', 'CBC_MCH', 'CBC_MCHC', 'CBC_Monocytes', 'CBC_PLATELET_COUNT', 'CBC_RDW', 'CBC_RED_BLOOD_CELL_COUNT', 'CBC_WHITE_BLOOD_CELL_COUNT', 'METABOLIC_ALBUMIN', 'METABOLIC_ALT_SGPT', 'METABOLIC_BILI_TOTAL', 'METABOLIC_BUN', 'METABOLIC_CALCIUM', 'METABOLIC_CARBON_DIOXIDE', 'METABOLIC_CHLORIDE', 'METABOLIC_CREATININE', 'METABOLIC_GLUCOSE', 'METABOLIC_POTASSIUM', 'METABOLIC_SODIUM', 'METABOLIC_TOTAL_PROTEIN', 'URINALYSIS_PH', 'URINALYSIS_RED_BLOOD_CELLS', 'URINALYSIS_WHITE_BLOOD_CELLS', 'Smoke', 'BMI', 'Alcohol', 'Exercise', 'Age']\n"
          ]
        }
      ],
      "source": [
        "# All columns used in training\n",
        "required_columns = X_train.columns.tolist()\n",
        "print(required_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User Input DataFrame:\n",
            "   AdmissionID PatientGender                 PrimaryDiagnosisDescription  \\\n",
            "0            5        Female  Type 2 diabetes mellitus with hypoglycemia   \n",
            "\n",
            "   CBC_Lymphocytes  CBC_Neutrophils  CBC_Basophils  CBC_Eosinophils  \\\n",
            "0              2.7              7.0            0.2              0.2   \n",
            "\n",
            "   CBC_Hematocrit  CBC_Hemoglobin  CBC_MCH  ...  METABOLIC_SODIUM  \\\n",
            "0            53.0            10.1     31.7  ...             134.5   \n",
            "\n",
            "   METABOLIC_TOTAL_PROTEIN  URINALYSIS_PH  URINALYSIS_RED_BLOOD_CELLS  \\\n",
            "0                      8.3            5.0                         0.4   \n",
            "\n",
            "   URINALYSIS_WHITE_BLOOD_CELLS  Smoke   BMI  Alcohol  Exercise  Age  \n",
            "0                           5.0    Yes  21.1      Yes       Yes   48  \n",
            "\n",
            "[1 rows x 36 columns]\n"
          ]
        }
      ],
      "source": [
        "# Provided sample data (single row)\n",
        "sample_data = {\n",
        "    'AdmissionID': [5],\n",
        "    'PatientGender': ['Female'],\n",
        "    'PrimaryDiagnosisDescription': ['Type 2 diabetes mellitus with hypoglycemia'],\n",
        "    'CBC_Lymphocytes': [2.7],\n",
        "    'CBC_Neutrophils': [7.0],\n",
        "    'CBC_Basophils': [0.2],\n",
        "    'CBC_Eosinophils': [0.2],\n",
        "    'CBC_Hematocrit': [53.0],\n",
        "    'CBC_Hemoglobin': [10.1],\n",
        "    'CBC_MCH': [31.7],\n",
        "    'CBC_MCHC': [33.9],\n",
        "    'CBC_Monocytes': [0.2],\n",
        "    'CBC_PLATELET_COUNT': [167.0],\n",
        "    'CBC_RDW': [13.9],\n",
        "    'CBC_RED_BLOOD_CELL_COUNT': [6.3],\n",
        "    'CBC_WHITE_BLOOD_CELL_COUNT': [7.8],\n",
        "    'METABOLIC_ALBUMIN': [3.0],\n",
        "    'METABOLIC_ALT_SGPT': [63.7],\n",
        "    'METABOLIC_BILI_TOTAL': [0.8],\n",
        "    'METABOLIC_BUN': [18.0],\n",
        "    'METABOLIC_CALCIUM': [8.4],\n",
        "    'METABOLIC_CARBON_DIOXIDE': [34.7],\n",
        "    'METABOLIC_CHLORIDE': [109.7],\n",
        "    'METABOLIC_CREATININE': [0.9],\n",
        "    'METABOLIC_GLUCOSE': [84.6],\n",
        "    'METABOLIC_POTASSIUM': [5.7],\n",
        "    'METABOLIC_SODIUM': [134.5],\n",
        "    'METABOLIC_TOTAL_PROTEIN': [8.3],\n",
        "    'URINALYSIS_PH': [5.0],\n",
        "    'URINALYSIS_RED_BLOOD_CELLS': [0.4],\n",
        "    'URINALYSIS_WHITE_BLOOD_CELLS': [5.0],\n",
        "    'Smoke': ['Yes'],\n",
        "    'BMI': [21.1],\n",
        "    'Alcohol': ['Yes'],\n",
        "    'Exercise': ['Yes'],\n",
        "    'Age': [48]\n",
        "}\n",
        "\n",
        "# Ensure all required columns are present in the input\n",
        "required_columns = ['AdmissionID', 'PatientGender', 'PrimaryDiagnosisDescription', 'CBC_Lymphocytes', 'CBC_Neutrophils', \n",
        "                    'CBC_Basophils', 'CBC_Eosinophils', 'CBC_Hematocrit', 'CBC_Hemoglobin', 'CBC_MCH', 'CBC_MCHC', \n",
        "                    'CBC_Monocytes', 'CBC_PLATELET_COUNT', 'CBC_RDW', 'CBC_RED_BLOOD_CELL_COUNT', \n",
        "                    'CBC_WHITE_BLOOD_CELL_COUNT', 'METABOLIC_ALBUMIN', 'METABOLIC_ALT_SGPT', 'METABOLIC_BILI_TOTAL', \n",
        "                    'METABOLIC_BUN', 'METABOLIC_CALCIUM', 'METABOLIC_CARBON_DIOXIDE', 'METABOLIC_CHLORIDE', \n",
        "                    'METABOLIC_CREATININE', 'METABOLIC_GLUCOSE', 'METABOLIC_POTASSIUM', 'METABOLIC_SODIUM', \n",
        "                    'METABOLIC_TOTAL_PROTEIN', 'URINALYSIS_PH', 'URINALYSIS_RED_BLOOD_CELLS', \n",
        "                    'URINALYSIS_WHITE_BLOOD_CELLS', 'Smoke', 'BMI', 'Alcohol', 'Exercise', 'Age']\n",
        "\n",
        "# Convert the sample data to a DataFrame\n",
        "user_input_df = pd.DataFrame(sample_data)\n",
        "\n",
        "# Add missing columns with NaN values\n",
        "for col in required_columns:\n",
        "    if col not in user_input_df.columns:\n",
        "        user_input_df[col] = np.nan\n",
        "\n",
        "# Ensure the columns are in the correct order\n",
        "user_input_df = user_input_df[required_columns]\n",
        "\n",
        "# Output the constructed user input DataFrame\n",
        "print(\"User Input DataFrame:\")\n",
        "print(user_input_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\HP\\\\Downloads'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Predicted Risk Score:\n",
            "4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8536\\4244912006.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(int(user_prediction.round()))\n"
          ]
        }
      ],
      "source": [
        "# Predict the risk score using the loaded and fitted pipeline\n",
        "user_prediction = loaded_pipeline.predict(user_input_df)\n",
        "\n",
        "# Output the prediction\n",
        "print(\"\\nPredicted Risk Score:\")\n",
        "print(int(user_prediction.round()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
